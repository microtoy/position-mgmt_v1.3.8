# -*- coding: utf-8 -*-
"""
é‚¢ä¸è¡Œï½œç­–ç•¥åˆ†äº«ä¼š
é€‰è‚¡ç­–ç•¥æ¡†æ¶ğ“Ÿğ“»ğ“¸

ç‰ˆæƒæ‰€æœ‰ Â©ï¸ é‚¢ä¸è¡Œ
å¾®ä¿¡: xbx1717

æœ¬ä»£ç ä»…ä¾›ä¸ªäººå­¦ä¹ ä½¿ç”¨ï¼Œæœªç»æˆæƒä¸å¾—å¤åˆ¶ã€ä¿®æ”¹æˆ–ç”¨äºå•†ä¸šç”¨é€”ã€‚

Author: é‚¢ä¸è¡Œ
"""
import copy
import itertools
import json
import operator
import os
import re
import warnings
from functools import reduce
from pathlib import Path
import pandas as pd

import tools.utils.pfunctions as pf
from core.utils.path_kit import get_folder_path, get_file_path
from tools.utils.unified_tool import UnifiedToolParam

warnings.filterwarnings("ignore")


# ====== å…¬å…±å‡½æ•° ======
def dict_itertools(dict_):
    keys = list(dict_.keys())
    values = list(dict_.values())
    return [dict(zip(keys, combo)) for combo in itertools.product(*values)]


def filter_dataframe(df, filter_dict):
    conditions = [df[col].isin(values) for col, values in filter_dict.items()]
    return df[reduce(operator.and_, conditions)] if conditions else df.copy()


def prepare_data():
    """ç”Ÿæˆå‚æ•°ç»„åˆå¹¶è¿‡æ»¤"""
    params_df = pd.DataFrame(dict_itertools(batch))
    params_df["å‚æ•°ç»„åˆ"] = [f"{trav_name}_å‚æ•°{i + 1}" for i in range(len(params_df))]
    df = filter_dataframe(params_df, limit_dict)
    # pivotçš„æ—¶å€™ä¸æ”¯æŒlistï¼Œæ‰€ä»¥æ­¤å¤„æŠŠlistæ”¹ä¸ºstr
    for k, v in batch.items():
        if any(isinstance(_, list) for _ in v):
            df[k] = df[k].astype("str")
    return df


def load_and_process_data(df_left, result_dir: Path):
    """åŠ è½½å¹¶å¤„ç†ç­–ç•¥è¯„ä»·æ•°æ®"""
    if evaluation_indicator not in [
        "ç´¯ç§¯å‡€å€¼",
        "å¹´åŒ–æ”¶ç›Š",
        "æœ€å¤§å›æ’¤",
        "å¹´åŒ–æ”¶ç›Š/å›æ’¤æ¯”",
        "ç›ˆåˆ©å‘¨æœŸæ•°",
        "äºæŸå‘¨æœŸæ•°",
        "èƒœç‡",
        "æ¯å‘¨æœŸå¹³å‡æ”¶ç›Š",
        "ç›ˆäºæ”¶ç›Šæ¯”",
        "å•å‘¨æœŸæœ€å¤§ç›ˆåˆ©",
        "å•å‘¨æœŸå¤§äºæŸ",
        "æœ€å¤§è¿ç»­ç›ˆåˆ©å‘¨æœŸæ•°",
        "æœ€å¤§è¿ç»­äºæŸå‘¨æœŸæ•°",
        "æ”¶ç›Šç‡æ ‡å‡†å·®",
    ]:
        raise ValueError("è¯„ä»·æŒ‡æ ‡æœ‰è¯¯ï¼ŒæŒ‰è¦æ±‚è¾“å…¥")

    if evaluation_indicator == "å¹´åŒ–æ”¶ç›Š":
        time_list = []
        for folder in df_left["å‚æ•°ç»„åˆ"]:
            # è¯»å–ç­–ç•¥è¯„ä»·æ•°æ®
            stats_path = result_dir / folder / "ç­–ç•¥è¯„ä»·.csv"
            stats_temp = pd.read_csv(stats_path, encoding="utf-8")
            stats_temp.columns = ["evaluation_indicator", "value"]
            if stats_temp.empty:
                raise ValueError(f"{folder} æ–‡ä»¶å¤¹å†…ç­–ç•¥è¯„ä»·æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®")
            stats_temp = stats_temp.set_index("evaluation_indicator")
            df_left.loc[df_left["å‚æ•°ç»„åˆ"] == folder, "all"] = stats_temp.loc[evaluation_indicator, "value"]

            # è¯»å–å¹´åº¦æ•°æ®
            years_path = result_dir / folder / "å¹´åº¦è´¦æˆ·æ”¶ç›Š.csv"
            years_return = pd.read_csv(years_path, encoding="utf-8")
            if years_return.empty:
                raise ValueError(f"{folder} æ–‡ä»¶å¤¹å†…å¹´åº¦è´¦æˆ·æ”¶ç›Šæ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®")
            time_list = list(years_return["candle_begin_time"].sort_values(ascending=False))
            for time in time_list:
                df_left.loc[df_left["å‚æ•°ç»„åˆ"] == folder, time] = years_return.loc[
                    years_return["candle_begin_time"] == time, "æ¶¨è·Œå¹…"
                ].iloc[0]

        # æ ¼å¼è½¬æ¢
        df_left[["all"] + time_list] = df_left[["all"] + time_list].map(
            lambda x: float(x.replace("%", "")) / 100 if "%" in str(x) else float(x)
        )
        return time_list
    else:
        for folder in df_left["å‚æ•°ç»„åˆ"]:
            stats_path = result_dir / folder / "ç­–ç•¥è¯„ä»·.csv"
            stats_temp = pd.read_csv(stats_path, encoding="utf-8")
            if stats_temp.empty:
                raise ValueError(f"{folder} æ–‡ä»¶å¤¹å†…ç­–ç•¥è¯„ä»·æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®")
            stats_temp.columns = ["evaluation_indicator", "value"]
            stats_temp = stats_temp.set_index("evaluation_indicator")
            df_left.loc[df_left["å‚æ•°ç»„åˆ"] == folder, evaluation_indicator] = stats_temp.loc[
                evaluation_indicator, "value"
            ]

        df_left[evaluation_indicator] = df_left[evaluation_indicator].apply(
            lambda x: float(x.replace("%", "")) / 100 if "%" in str(x) else float(x)
        )
        return None


def generate_plots(df_left, params, output_dir: Path, analysis_type, time_list):
    """æ ¹æ®åˆ†æç±»å‹ç”Ÿæˆå›¾è¡¨"""
    fig_list = []
    html_name = f"å¹´åŒ–æ”¶ç›Š_å›æ’¤æ¯”.html" if evaluation_indicator == "å¹´åŒ–æ”¶ç›Š/å›æ’¤æ¯”" else f"{evaluation_indicator}.html"

    if "hold_period" in df_left.columns:
        df_left["periods"] = df_left["hold_period"].apply(lambda x: int(x[:-1]))
        df_left = df_left.sort_values(by=["periods"])

    if analysis_type == "double":
        x_, y_ = params

        if evaluation_indicator == "å¹´åŒ–æ”¶ç›Š":
            for time in ["all"] + time_list:
                temp = pd.pivot_table(df_left, index=y_, columns=x_, values=time)
                fig = pf.draw_params_heatmap_plotly(temp, title=time)
                fig_list.append(fig)
        else:
            temp = pd.pivot_table(df_left, index=y_, columns=x_, values=evaluation_indicator)
            fig = pf.draw_params_heatmap_plotly(temp, title=evaluation_indicator)
            fig_list.append(fig)
        html_name = f"{x_}_{y_}_{html_name}"

    else:
        param = params
        if evaluation_indicator == "å¹´åŒ–æ”¶ç›Š":
            sub_df = df_left[[param] + ["all"] + time_list].copy()
            sub_df[param] = sub_df[param].map(lambda x: f"{param}_{x}")
            sub_df = sub_df.set_index(param)
            fig = pf.draw_params_bar_plotly(sub_df, evaluation_indicator)
        else:
            x_axis = df_left[param].map(lambda x: f"{param}_{x}")
            fig = pf.draw_bar_plotly(
                x_axis, df_left[evaluation_indicator], title=evaluation_indicator, pic_size=[1800, 600]
            )
        fig_list.append(fig)
        html_name = f"{param}_{html_name}"

    if fig_list:
        title = "å‚æ•°çƒ­åŠ›å›¾" if analysis_type == "double" else "å‚æ•°å¹³åŸå›¾"
        pf.merge_html_flexible(fig_list, output_dir / html_name, title=title)

    return output_dir / html_name


# ====== ä¸»é€»è¾‘ ======
def analyze_params(analysis_type):
    """å‚æ•°åˆ†æä¸»å‡½æ•°"""
    df_left = prepare_data()

    # é…ç½®è¾“å‡ºè·¯å¾„
    if analysis_type == "double":
        output_dir = out_folder_path / "å‚æ•°çƒ­åŠ›å›¾" / trav_name
        params = [param_x, param_y]
    else:
        output_dir = out_folder_path / "å‚æ•°å¹³åŸå›¾" / trav_name
        params = param_x
    os.makedirs(output_dir, exist_ok=True)

    # å¤„ç†æ•°æ®
    time_list = load_and_process_data(df_left, result_folder_path)

    # ç”Ÿæˆå›¾è¡¨
    html_path = generate_plots(df_left, params, output_dir, analysis_type, time_list)

    return dict(
        name="å‚æ•°çƒ­åŠ›å›¾" if analysis_type == "double" else "å‚æ•°å¹³åŸå›¾",
        html=str(html_path).split(f'{os.path.sep}åˆ†æç»“æœ')[1],
        full_path=str(html_path)
    )


def __load_and_clean_config():
    """åŠ è½½å¹¶æ¸…ç†é…ç½®æ–‡ä»¶

    Returns:
        tuple: (trav_name, strategy_list, batch)
    """
    with open(get_file_path("config.json"), "r", encoding="utf-8") as f:
        data_json = json.load(f)

    search_name = data_json.get("search_name", "éå†")
    stg = data_json.get("strategy_info", {}).get("strategy_config", {})

    # æ¸…ç†batchæ•°æ®ï¼šç§»é™¤nameã€search_nameã€strategy_infoè¿™ä¸‰ä¸ªkeyï¼Œä»¥åŠvalueä¸å­˜åœ¨çš„æ•°æ®
    keys_to_remove = ["name", "search_name", "strategy_info"]
    for key in keys_to_remove:
        data_json.pop(key, None)  # å®‰å…¨ç§»é™¤ï¼Œå¦‚æœkeyä¸å­˜åœ¨ä¸ä¼šæŠ¥é”™

    # ç§»é™¤valueä¸å­˜åœ¨çš„æ•°æ®ï¼ˆNoneã€ç©ºå­—ç¬¦ä¸²ã€ç©ºlistç­‰ï¼‰
    data_json = {
        k: v
        for k, v in data_json.items()
        if v is not None and v != "" and v != [] and v != {}
    }

    return search_name, stg, data_json


def __parse_path_expression(path_expr):
    """è§£æè·¯å¾„è¡¨è¾¾å¼ï¼Œå¦‚ 'factor_list[0][2][0]'

    Args:
        path_expr: è·¯å¾„è¡¨è¾¾å¼å­—ç¬¦ä¸²

    Returns:
        tuple: (base_key, indices)
        - base_key: åŸºç¡€é”®åï¼Œå¦‚ 'factor_list'
        - indices: ç´¢å¼•åˆ—è¡¨ï¼Œå¦‚ [0, 2, 0]
    """
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…åŸºç¡€é”®åå’Œæ‰€æœ‰ç´¢å¼•
    match = re.match(r"^([^[]+)((?:\[\d+\])+)$", path_expr)
    if not match:
        return path_expr, []

    base_key = match.group(1)
    indices_str = match.group(2)

    # æå–æ‰€æœ‰æ•°å­—ç´¢å¼•
    indices = [int(idx) for idx in re.findall(r"\[(\d+)\]", indices_str)]

    return base_key, indices


def __resolve_factor_name(path_expr, strategy_dict):
    """è§£æè·¯å¾„è¡¨è¾¾å¼å¹¶è·å–å› å­åç§°

    Args:
        path_expr: è·¯å¾„è¡¨è¾¾å¼å­—ç¬¦ä¸²ï¼Œå¦‚ 'factor_list[0][2][1]'
        strategy_dict: ç­–ç•¥ä¿¡æ¯å­—å…¸

    Returns:
        str or None: è§£æåçš„å› å­åç§°ï¼ˆå¸¦åç¼€ï¼‰ï¼Œå¦‚æœè§£æå¤±è´¥è¿”å›None
    """
    base_key, indices = __parse_path_expression(path_expr)

    if base_key and len(indices) >= 2:
        # è·å– factor_list æˆ– filter_list
        factor_list = strategy_dict.get('params', {}).get(base_key, [])

        if len(factor_list) > indices[0]:
            # è·å–å› å­é…ç½® factor_list[0]
            factor_config = factor_list[indices[0]]

            # è·å–å› å­åç§° factor_list[0][0]
            factor_name = factor_config[0]

            # è§£å†³ä¸€ä¸ªå› å­çš„å‚æ•°æ˜¯åˆ—è¡¨çš„é—®é¢˜
            factor_name = f"{factor_name}_{indices[0]}_{indices[-1]}"

            return factor_name
        else:
            print(f"Warning: æœªæ£€æµ‹åˆ°å› å­é…ç½® {path_expr}")
            return None
    else:
        # ä¸æ˜¯è·¯å¾„è¡¨è¾¾å¼
        return None


def convert_lists_to_tuples(data, target_fields=None):
    """é€’å½’åœ°å°†æŒ‡å®šå­—æ®µä¸­çš„åˆ—è¡¨é‡Œçš„åˆ—è¡¨è½¬æ¢ä¸ºå…ƒç»„

    é’ˆå¯¹config.jsonæ•°æ®ä¸­strategy_info->strategy_config->paramsé‡Œé¢çš„factor_listè¿›è¡Œè½¬åŒ–

    Args:
        data: å­—å…¸æ•°æ®æˆ–å…¶ä»–æ•°æ®ç±»å‹
        target_fields: éœ€è¦å¤„ç†çš„å­—æ®µé›†åˆï¼Œé»˜è®¤ä¸ºNoneæ—¶å¤„ç†æ‰€æœ‰å­—æ®µ

    Returns:
        å¤„ç†åçš„æ•°æ®
    """
    # é»˜è®¤çš„å…ƒç»„å­—æ®µ
    if target_fields is None:
        target_fields = {
            "factor_list",
            "long_factor_list",
            "short_factor_list",
            "filter_list",
            "long_filter_list",
            "short_filter_list",
            "filter_list_post",
            "long_filter_list_post",
            "short_filter_list_post",
        }

    # å¦‚æœä¸æ˜¯å­—å…¸ï¼Œç›´æ¥è¿”å›
    if not isinstance(data, dict):
        return data

    # æ·±æ‹·è´ä»¥é¿å…ä¿®æ”¹åŸæ•°æ®
    result = copy.deepcopy(data)

    # é€’å½’å¤„ç†æ‰€æœ‰é”®å€¼å¯¹
    for key, value in result.items():
        if isinstance(value, dict):
            # å¦‚æœå€¼æ˜¯å­—å…¸ï¼Œé€’å½’å¤„ç†
            result[key] = convert_lists_to_tuples(value, target_fields)
        elif key in target_fields and isinstance(value, list):
            # å¦‚æœæ˜¯ç›®æ ‡å­—æ®µä¸”å€¼æ˜¯åˆ—è¡¨ï¼Œè½¬æ¢å†…éƒ¨çš„åˆ—è¡¨ä¸ºå…ƒç»„
            result[key] = [
                tuple(item) if isinstance(item, list) else item
                for item in value
            ]

    return result


def convert_range_params(data):
    """è½¬æ¢rangeæ ¼å¼çš„å‚æ•°ä¸ºåˆ—è¡¨

    Args:
        data: é…ç½®æ•°æ®ï¼ˆé€šå¸¸æ˜¯å­—å…¸ï¼‰

    Returns:
        è½¬æ¢åçš„æ•°æ®
    """
    if isinstance(data, dict):
        # æ£€æŸ¥æ˜¯å¦æ˜¯rangeæ ¼å¼ {"start": x, "end": y, "step": z}
        if all(key in data for key in ["start", "end", "step"]):
            start = data["start"]
            end = data["end"]
            step = data["step"]
            return list(range(start, end, step))
        else:
            # é€’å½’å¤„ç†å­—å…¸ä¸­çš„æ¯ä¸ªå€¼
            return {k: convert_range_params(v) for k, v in data.items()}
    elif isinstance(data, list):
        # é€’å½’å¤„ç†åˆ—è¡¨ä¸­çš„æ¯ä¸ªå…ƒç´ 
        return [convert_range_params(item) for item in data]
    else:
        # å…¶ä»–ç±»å‹ç›´æ¥è¿”å›
        return data


if __name__ == "__main__":
    # ====== ä½¿ç”¨è¯´æ˜ ======
    "https://bbs.quantclass.cn/thread/54137"

    # ====== é…ç½®ä¿¡æ¯ ======
    trav_name = "BTCæ‹©æ—¶ç­–ç•¥"  # ç”¨äºè¯»å– data/éå†ç»“æœ/ ä¸­çš„éå†å›æµ‹ç»“æœ

    # å›æµ‹è·¯å¾„å’Œå‚æ•°åˆ†æè¾“å‡ºè·¯å¾„
    result_folder_path = get_folder_path("data", "ä»“ä½ç®¡ç†å›æµ‹ç»“æœ", trav_name, as_path_type=True, auto_create=False)
    out_folder_path = get_folder_path("data", "åˆ†æç»“æœ", "å‚æ•°åˆ†æ", as_path_type=True)

    # å‚æ•°è®¾ç½®
    batch = {
        "cci": range(6, 30, 5),
        # "long": [250, 260],
        # "max_select_num": [5],
    }

    # è‹¥ç»˜åˆ¶å•å‚æ•°å¹³åŸå›¾ï¼Œparam_x å¡«å†™å˜é‡ï¼Œparam_y=''
    # è‹¥ç»˜åˆ¶åŒå‚æ•°çƒ­åŠ›å›¾ï¼Œåˆ™ param_xå’Œparam_y å¡«å†™å˜é‡, param_ä¸ºçƒ­åŠ›å›¾xè½´å˜é‡ï¼Œparam_yä¸ºçƒ­åŠ›å›¾yè½´å˜é‡ï¼Œå¯æŒ‰éœ€æ›´æ”¹
    param_x = "cci"
    # param_y = "long"
    param_y = ""

    # è¿™é‡Œéœ€è¦å›ºå®šéè§‚æµ‹å‚æ•°ï¼Œç„¶åç”»å‚æ•°å›¾ï¼Œä¾‹å¦‚è¯¥æ¡ˆä¾‹å›ºå®šhold_period== 12Hï¼Œæ¥çœ‹LowPriceå’ŒQuoteVolumeMeançš„å‚æ•°çƒ­åŠ›å›¾
    # æ³¨æ„ç‚¹ï¼šå¤šå‚æ•°ç”»å›¾ï¼Œå¿…é¡»å›ºå®šå…¶ä»–å‚æ•°ã€‚å•å‚æ•°å¹³åŸéœ€å›ºå®šè¯¥å‚æ•°ä»¥å¤–çš„å…¶ä»–å‚æ•°ï¼ŒåŒå‚æ•°çƒ­åŠ›å›¾éœ€å›ºå®šé™¤ä¸¤å‚æ•°ä»¥å¤–çš„å‚æ•°
    limit_dict = {
        # 'LowPrice': [48],
        # 'hold_period': ["12H"],
        # 'QuoteVolumeMean': [48],
        # "short": [10],
        # "long": [250],
        # 'max_select_num': [10],
    }

    # åˆ†ææŒ‡æ ‡ï¼Œæ”¯æŒä»¥ä¸‹ï¼š
    # ç´¯ç§¯å‡€å€¼ã€å¹´åŒ–æ”¶ç›Šã€æœ€å¤§å›æ’¤ã€å¹´åŒ–æ”¶ç›Š/å›æ’¤æ¯”ã€ç›ˆåˆ©å‘¨æœŸæ•°ã€äºæŸå‘¨æœŸæ•°ã€èƒœç‡ã€æ¯å‘¨æœŸå¹³å‡æ”¶ç›Š
    # ç›ˆäºæ”¶ç›Šæ¯”ã€å•å‘¨æœŸæœ€å¤§ç›ˆåˆ©ã€å•å‘¨æœŸå¤§äºæŸã€æœ€å¤§è¿ç»­ç›ˆåˆ©å‘¨æœŸæ•°ã€æœ€å¤§è¿ç»­äºæŸå‘¨æœŸæ•°ã€æ”¶ç›Šç‡æ ‡å‡†å·®
    evaluation_indicator = "å¹´åŒ–æ”¶ç›Š"

    # ====== ä¸»é€»è¾‘ ======
    INPUT = [
        {
            "name": "param_search_info",
            "reflect": "param_search_info",
        }
    ]
    param_search_info = {}
    unified_tool_param = UnifiedToolParam(name=Path(__file__).stem)
    ui_input = unified_tool_param.get_input_json()
    if ui_input:
        for input_param in INPUT:
            attr_name = input_param["name"]
            ui_name = input_param["reflect"]
            globals()[attr_name] = ui_input[ui_name]

    # éå†çš„ç­–ç•¥ä¿¡æ¯
    if param_search_info:
        trav_name, strategy_info, batch = __load_and_clean_config()
        strategy_info = convert_lists_to_tuples(strategy_info)
        # é‡ç½®ä¸€ä¸‹æ–‡ä»¶è·¯å¾„
        result_folder_path = get_folder_path(
            "data", "ä»“ä½ç®¡ç†å›æµ‹ç»“æœ", trav_name, auto_create=False, as_path_type=True
        )
        for _key, _value in param_search_info.items():

            if _key in ["param_x", "param_y"]:
                # å°è¯•è§£æè·¯å¾„è¡¨è¾¾å¼å¹¶è·å–å› å­åç§°
                factor_name = __resolve_factor_name(_value, strategy_info)

                if factor_name:
                    # æˆåŠŸè§£æä¸ºå› å­åç§°
                    globals()[_key] = factor_name
                else:
                    # ä¸æ˜¯è·¯å¾„è¡¨è¾¾å¼æˆ–è§£æå¤±è´¥ï¼Œç›´æ¥èµ‹å€¼
                    globals()[_key] = _value
            elif _key == "limit_dict":
                # å¤„ç† limit_dictï¼šè§£æè·¯å¾„è¡¨è¾¾å¼ï¼Œç”¨å› å­åç§°æ›¿æ¢åŸæ¥çš„key
                processed_limit_dict = {}
                for limit_key, limit_value in _value.items():
                    # å°è¯•è§£æè·¯å¾„è¡¨è¾¾å¼å¹¶è·å–å› å­åç§°
                    factor_name = __resolve_factor_name(limit_key, strategy_info)

                    if factor_name:
                        # ç”¨å› å­åç§°ä½œä¸ºæ–°çš„key
                        processed_limit_dict[factor_name] = limit_value
                    else:
                        # å¦‚æœä¸æ˜¯è·¯å¾„è¡¨è¾¾å¼æˆ–è§£æå¤±è´¥ï¼Œä¿æŒåŸkey
                        processed_limit_dict[limit_key] = limit_value

                globals()[_key] = processed_limit_dict
            else:
                globals()[_key] = _value

        # å¤„ç†batchä¸­çš„è·¯å¾„è¡¨è¾¾å¼keyï¼Œè½¬æ¢ä¸ºå› å­åç§°
        processed_batch = {}
        for batch_key, batch_value in batch.items():
            # å°è¯•è§£æè·¯å¾„è¡¨è¾¾å¼å¹¶è·å–å› å­åç§°
            factor_name = __resolve_factor_name(batch_key, strategy_info)

            if factor_name:
                # ç”¨å› å­åç§°ä½œä¸ºæ–°çš„key
                processed_batch[factor_name] = convert_range_params(batch_value)
            else:
                # å¦‚æœä¸æ˜¯è·¯å¾„è¡¨è¾¾å¼æˆ–è§£æå¤±è´¥ï¼Œä¿æŒåŸkey
                processed_batch[batch_key] = convert_range_params(batch_value)

        # æ›´æ–°å…¨å±€çš„batchå˜é‡
        batch = processed_batch

    # è¿›è¡Œå‚æ•°åˆ†æ
    analysis_type = "single" if len(param_y.strip()) == 0 else "double"
    ui_output = analyze_params(analysis_type)

    unified_tool_param.save_output_json([ui_output])
