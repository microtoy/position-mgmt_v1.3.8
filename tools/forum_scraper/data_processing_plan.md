
# 数据后续处理与 NotebookLM 导入计划

本文档记录了在完成 4000+ 篇量化研报爬取后的数据清洗与知识库构建方案。

## 1. 爬取现状
- **数据源**: 宽邦量化社区 (bbs.quantclass.cn)
- **格式**: 高清 PDF (截图转 PDF 方案，Headless=False)
- **存储路径**: `tools/forum_scraper/downloaded_pdfs/`
- **特点**: 所见即所得，包含完整代码、K线图、回测曲线，无样式遮挡。

## 2. 挑战与解决方案
**挑战**: NotebookLM (AI Premium) 虽然支持 300 个源文件，但无法直接容纳 4000+ 个独立 PDF 文件。
**解决方案**: **“巨型合集”合并策略**。

## 3. 待执行脚本: `merge_pdfs.py` (计划中)
在爬虫任务彻底完成后，将开发此脚本。

### 功能规划
1. **自动扫描**: 遍历 `downloaded_pdfs` 目录。
2. **智能分组**:
   - **方案 A (按数量)**: 每 50-100 篇合并为一个 PDF (约 100-200MB)。
   - **方案 B (按年份)**: 解析文件名或元数据，生成 `2023_全集.pdf`, `2022_全集.pdf`。
   - **方案 C (按主题)**: 根据文件名关键词 (如 "股票", "数字货币", "因子") 分类合并。
3. **目录生成**: 
   - 合并后的 PDF 首页将自动生成**可跳转的目录 (TOC)**，点击标题直接跳转到对应研报页。
   - *这是 NotebookLM 理解长文档结构的关键。*
4. **输出**: `tools/forum_scraper/merged_books/`

## 4. NotebookLM 知识库构建指南

### 步骤 A: 上传
将合并后的 `Batch_01.pdf` 至 `Batch_XX.pdf` 上传至 NotebookLM。

### 步骤 B: 提示词工程 (Prompting)
为了让 AI 更好地从这些合集中提取策略，建议使用以下 Prompt 结构：

**场景 1：策略提取**
> "请检索《2023_股票策略合集》中关于'动量因子'的所有文章。总结并对比不同作者对动量因子的改进思路（如衰减加权、剔除新股等），并给出具体的 Python 实现代码逻辑。"

**场景 2：图表分析**
> "查看文档中所有年化收益率超过 30% 的回测截图。分析这些策略的共同特征是什么？它们的回撤通常发生在什么市场环境下？"

## 5. 待办事项 (ToDo)
- [ ] 等待 4000+ 篇 PDF 全部爬取完成 (约需数天)。
- [ ] 编写 `merge_pdfs.py`。
- [ ] 执行合并，验证目录跳转功能。
- [ ] 上传测试。
