"""
é‚¢ä¸è¡Œï½œç­–ç•¥åˆ†äº«ä¼š
ä»“ä½ç®¡ç†æ¡†æ¶

ç‰ˆæƒæ‰€æœ‰ Â©ï¸ é‚¢ä¸è¡Œ
å¾®ä¿¡: xbx1717

æœ¬ä»£ç ä»…ä¾›ä¸ªäººå­¦ä¹ ä½¿ç”¨ï¼Œæœªç»æˆæƒä¸å¾—å¤åˆ¶ã€ä¿®æ”¹æˆ–ç”¨äºå•†ä¸šç”¨é€”ã€‚

Author: é‚¢ä¸è¡Œ
"""
import logging
import shutil
import time

import pandas as pd

from config import job_num, raw_data_path, backtest_path
from core.equity import calc_equity, show_plot_performance
from core.model.backtest_config import BacktestConfig
from core.model.backtest_config import BacktestConfigFactory
from core.model.timing_signal import TimingSignal
from core.select_coin import calc_factors, select_coins, concat_select_results, process_select_results, \
    agg_multi_strategy_ratio, calc_cross_sections
from core.utils.functions import load_spot_and_swap_data, save_performance_df_csv
from core.utils.log_kit import logger, divider


def step2_load_data(conf: BacktestConfig):
    """
    è¯»å–å›æµ‹æ‰€éœ€æ•°æ®ï¼Œå¹¶åšç®€å•çš„é¢„å¤„ç†
    :param conf:
    :return:
    """
    logger.info(f'è¯»å–æ•°æ®ä¸­å¿ƒæ•°æ®...')
    s_time = time.time()

    # è¯»å–æ•°æ®
    # é’ˆå¯¹ç°è´§ç­–ç•¥å’Œéç°è´§ç­–ç•¥è¯»å–çš„é€»è¾‘å®Œå…¨ä¸åŒã€‚
    # - å¦‚æœæ˜¯çº¯åˆçº¦æ¨¡å¼ï¼Œåªéœ€è¦è¯»å…¥ swap æ•°æ®å¹¶ä¸”åˆå¹¶å³å¯
    # - å¦‚æœæ˜¯ç°è´§æ¨¡å¼ï¼Œéœ€è¦è¯»å…¥ spot å’Œ swap æ•°æ®å¹¶ä¸”åˆå¹¶ï¼Œç„¶åæ·»åŠ  tag
    load_spot_and_swap_data(conf)  # ä¸²è¡Œæ–¹å¼ï¼Œå®Œå…¨ç­‰ä»·
    logger.ok(f'å®Œæˆè¯»å–æ•°æ®ä¸­å¿ƒæ•°æ®ï¼ŒèŠ±è´¹æ—¶é—´ï¼š{time.time() - s_time:.2f}ç§’')


def step3_calc_factors(conf: BacktestConfig):
    """
    è®¡ç®—å› å­
    :param conf: é…ç½®
    :return:
    """
    s_time = time.time()
    logger.info(f'æ—¶åºå› å­è®¡ç®—...')
    calc_factors(conf)
    logger.ok(f'å®Œæˆè®¡ç®—æ—¶åºå› å­ï¼ŒèŠ±è´¹æ—¶é—´ï¼š{time.time() - s_time:.2f}ç§’')

    # è®¡ç®—æˆªé¢å› å­
    logger.info('æˆªé¢å› å­è®¡ç®—...')
    s_time = time.time()
    calc_cross_sections(conf)
    logger.ok(f'å®Œæˆè®¡ç®—æˆªé¢å› å­ï¼ŒèŠ±è´¹æ—¶é—´ï¼š{time.time() - s_time:.2f}ç§’')


def step4_select_coins(conf: BacktestConfig):
    """
    é€‰å¸
    :param conf: é…ç½®
    :return:
    """
    s_time = time.time()
    logger.info(f'é€‰å¸...')
    select_coins(conf)  # é€‰å¸
    logger.ok(f'å®Œæˆé€‰å¸ï¼ŒèŠ±è´¹æ—¶é—´ï¼š{time.time() - s_time:.3f}ç§’')


def step5_aggregate_select_results(conf: BacktestConfig, save_final_result=False):
    logger.info(f'æ•´ç†{conf.name}é€‰å¸ç»“æœ...')
    # æ•´ç†é€‰å¸ç»“æœ
    concat_select_results(conf)  # åˆå¹¶å¤šä¸ªç­–ç•¥çš„é€‰å¸ç»“æœ
    select_results = process_select_results(conf)  # ç”Ÿæˆæ•´ç†åçš„é€‰å¸ç»“æœ
    logger.debug(f'ğŸ’¾ {conf.name}é€‰å¸ç»“æœdfå¤§å°ï¼š'
                 f'{select_results.memory_usage(deep=True).sum() / 1024 / 1024 / 1024:.4f} G')
    if save_final_result:
        # å­˜å‚¨æœ€ç»ˆçš„é€‰å¸ç»“æœ
        select_results.to_pickle(backtest_path / 'final_select_results.pkl')

    # èšåˆå¤§æ‚çƒ©ä¸­å¤šç­–ç•¥çš„æƒé‡ï¼Œä»¥åŠå¤šoffseté€‰å¸çš„æƒé‡èšåˆ
    s_time = time.time()
    logger.debug(f'ğŸ”ƒ å¼€å§‹{conf.name}æƒé‡èšåˆ...')
    df_spot_ratio, df_swap_ratio = agg_multi_strategy_ratio(conf, select_results)

    # å§‹ç»ˆè¾“å‡ºratios
    df_spot_ratio.to_pickle(conf.get_result_folder() / 'df_spot_ratio.pkl')
    df_swap_ratio.to_pickle(conf.get_result_folder() / 'df_swap_ratio.pkl')

    logger.ok(f'å®Œæˆ{conf.name}æƒé‡èšåˆï¼ŒèŠ±è´¹æ—¶é—´ï¼š {time.time() - s_time:.3f}ç§’')
    return df_spot_ratio, df_swap_ratio


def step6_simulate_performance(conf: BacktestConfig, df_spot_ratio, df_swap_ratio, pivot_dict_spot, pivot_dict_swap,
                               if_show_plot=False, extra_equities=None, description=None):
    logger.info(f'{conf.name} å¼€å§‹æ¨¡æ‹Ÿäº¤æ˜“...')
    if extra_equities is None:
        extra_equities = {}
    logger.debug(f'ğŸ“… [{conf.name}] æ¨¡æ‹Ÿäº¤æ˜“ï¼Œå›æº¯ {len(df_spot_ratio):,} å°æ—¶ï¼ˆ~{len(df_spot_ratio) / 24:,.0f}å¤©ï¼‰...')
    account_df, rtn, year_return, month_return, quarter_return = calc_equity(
        conf, pivot_dict_spot, pivot_dict_swap,
        df_spot_ratio, df_swap_ratio
    )
    save_performance_df_csv(conf,
                            èµ„é‡‘æ›²çº¿=account_df,
                            ç­–ç•¥è¯„ä»·=rtn,
                            å¹´åº¦è´¦æˆ·æ”¶ç›Š=year_return,
                            å­£åº¦è´¦æˆ·æ”¶ç›Š=quarter_return,
                            æœˆåº¦è´¦æˆ·æ”¶ç›Š=month_return)

    has_timing_signal = isinstance(conf.timing, TimingSignal)
    prefix = ''

    if has_timing_signal:
        account_df, rtn, year_return = simu_timing(conf, df_spot_ratio, df_swap_ratio, pivot_dict_spot,
                                                   pivot_dict_swap)
        prefix = 'å†æ‹©æ—¶: '

    if if_show_plot:
        show_plot_performance(conf, account_df, rtn, year_return, prefix, description=description, **extra_equities)

    return conf.report


def simu_timing(conf: BacktestConfig, df_spot_ratio, df_swap_ratio, pivot_dict_spot, pivot_dict_swap):
    s_time = time.time()
    logger.info(f'{conf.get_fullname(as_folder_name=True)} èµ„é‡‘æ›²çº¿æ‹©æ—¶ï¼Œç”ŸæˆåŠ¨æ€æ æ†')

    account_df = pd.read_csv(conf.get_result_folder() / 'èµ„é‡‘æ›²çº¿.csv', index_col=0, encoding='utf-8-sig')

    # æ£€æŸ¥å“ªä¸ªåŠ¨æ€æ æ†æ–¹æ³•æœ‰å®ç°ï¼Œä¼˜å…ˆä½¿ç”¨ get_dynamic_leverage_for_dataframe
    if conf.timing.impl_flags.get('dynamic_leverage_for_dataframe', False):
        leverages = conf.timing.get_dynamic_leverage_for_dataframe(account_df)
    elif conf.timing.impl_flags.get('dynamic_leverage', False):
        leverages = conf.timing.get_dynamic_leverage(account_df['equity'])
    else:
        raise NotImplementedError(f'æ‹©æ—¶ä¿¡å· {conf.timing.name} å¿…é¡»å®ç° dynamic_leverage æˆ– dynamic_leverage_for_dataframe æ–¹æ³•ä¹‹ä¸€')

    account_df, rtn, year_return, month_return, quarter_return = calc_equity(
        conf, pivot_dict_spot, pivot_dict_swap, df_spot_ratio, df_swap_ratio, leverages * conf.leverage
    )
    save_performance_df_csv(
        conf,
        èµ„é‡‘æ›²çº¿_å†æ‹©æ—¶=account_df,
        ç­–ç•¥è¯„ä»·_å†æ‹©æ—¶=rtn,
        å¹´åº¦è´¦æˆ·æ”¶ç›Š_å†æ‹©æ—¶=year_return,
        å­£åº¦è´¦æˆ·æ”¶ç›Š_å†æ‹©æ—¶=quarter_return,
        æœˆåº¦è´¦æˆ·æ”¶ç›Š_å†æ‹©æ—¶=month_return,
        å†æ‹©æ—¶åŠ¨æ€æ æ†=pd.DataFrame({
            'candle_begin_time': account_df['candle_begin_time'],
            'åŠ¨æ€æ æ†': leverages
        })
    )
    logger.debug(f'â° å®Œæˆå†æ‹©æ—¶æ¨¡æ‹Ÿè®¡ç®—ï¼Œå·²èŠ±è´¹æ—¶é—´{time.time() - s_time:.3f}ç§’')

    return account_df, rtn, year_return


def load_pivot_data(base_path, market_type):
    """ä» Parquet åŠ è½½ Pivot æ•°æ® (V2 ä¼˜åŒ–)"""
    res = {}
    prefix = f'market_pivot_{market_type}'
    import polars as pl
    for pq_file in base_path.glob(f"{prefix}_*.parquet"):
        key = pq_file.stem.replace(f"{prefix}_", "")
        # V2 ä¿®æ­£: ä½¿ç”¨ Polars åŠ è½½åå†è½¬ Pandasï¼Œå¹¶æ¢å¤ DatetimeIndex
        df = pl.read_parquet(pq_file).to_pandas()
        if 'candle_begin_time' in df.columns:
            df['candle_begin_time'] = pd.to_datetime(df['candle_begin_time'])
            df.set_index('candle_begin_time', inplace=True)
        res[key] = df
    return res


def simu_performance_on_select(conf: BacktestConfig, silent=True, pivot_dict_spot=None, pivot_dict_swap=None):
    import logging
    if silent:
        logger.setLevel(logging.WARNING)  # å¯ä»¥å‡å°‘ä¸­é—´è¾“å‡ºçš„log
    # ====================================================================================================
    # 5. æ•´ç†å¤§æ‚çƒ©é€‰å¸ç»“æœ
    # - æŠŠå¤§æ‚çƒ©ä¸­æ¯ä¸€ä¸ªç­–ç•¥çš„é€‰å¸ç»“æœèšåˆæˆä¸€ä¸ªdf
    # ====================================================================================================
    df_spot_ratio, df_swap_ratio = step5_aggregate_select_results(conf)

    # V2 ä¼˜åŒ–: ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„ Pivot æ•°æ®ï¼Œå‡å°‘ç£ç›˜ I/O
    if pivot_dict_spot is None:
        pivot_dict_spot = load_pivot_data(raw_data_path, 'spot')
        if not pivot_dict_spot:
            pivot_dict_spot = pd.read_pickle(raw_data_path / 'market_pivot_spot.pkl')
    
    if pivot_dict_swap is None:
        pivot_dict_swap = load_pivot_data(raw_data_path, 'swap')
        if not pivot_dict_swap:
            pivot_dict_swap = pd.read_pickle(raw_data_path / 'market_pivot_swap.pkl')

    res = step6_simulate_performance(conf, df_spot_ratio, df_swap_ratio, pivot_dict_spot, pivot_dict_swap)
    logger.setLevel(logging.DEBUG)  # ä¸­é—´ç»“æœæ¢å¤ä¸€ä¸‹
    return res


# ====================================================================================================
# ** å›æµ‹ä¸»ç¨‹åº **
# 1. å‡†å¤‡å·¥ä½œ
# 2. è¯»å–æ•°æ®
# 3. è®¡ç®—å› å­
# 4. é€‰å¸
# 5. æ•´ç†é€‰å¸æ•°æ®
# 6. æ·»åŠ ä¸‹ä¸€ä¸ªæ¯ä¸€ä¸ªå‘¨æœŸéœ€è¦å–å‡ºçš„å¸çš„ä¿¡æ¯
# 7. è®¡ç®—èµ„é‡‘æ›²çº¿
# ====================================================================================================
def run_backtest(conf: BacktestConfig):
    # ====================================================================================================
    # 1. å‡†å¤‡å·¥ä½œ
    # ====================================================================================================
    divider(conf.name, '*')

    # åˆ é™¤ç¼“å­˜
    conf.delete_cache()

    # è®°å½•ä¸€ä¸‹æ—¶é—´æˆ³
    r_time = time.time()

    # ç¼“å­˜å½“å‰çš„config
    conf.save()

    # ====================================================================================================
    # 2. è¯»å–å›æµ‹æ‰€éœ€æ•°æ®ï¼Œå¹¶åšç®€å•çš„é¢„å¤„ç†
    # ====================================================================================================
    step2_load_data(conf)

    # ====================================================================================================
    # 3. è®¡ç®—å› å­
    # ====================================================================================================
    step3_calc_factors(conf)

    # ====================================================================================================
    # 4. é€‰å¸
    # - æ³¨æ„ï¼šé€‰å®Œä¹‹åï¼Œæ¯ä¸€ä¸ªç­–ç•¥çš„é€‰å¸ç»“æœä¼šè¢«ä¿å­˜åˆ°ç¡¬ç›˜
    # ====================================================================================================
    step4_select_coins(conf)

    # ====================================================================================================
    # 5. æ•´ç†é€‰å¸ç»“æœå¹¶å½¢æˆç›®æ ‡æŒä»“
    # ====================================================================================================
    df_spot_ratio, df_swap_ratio = step5_aggregate_select_results(conf)
    logger.ok(f'ç›®æ ‡æŒä»“ä¿¡å·å·²å®Œæˆï¼ŒèŠ±è´¹æ—¶é—´ï¼š{(time.time() - r_time):.3f}ç§’')

    # ====================================================================================================
    # 6. æ ¹æ®ç›®æ ‡æŒä»“è®¡ç®—èµ„é‡‘æ›²çº¿
    # ====================================================================================================
    pivot_dict_spot = load_pivot_data(raw_data_path, 'spot')
    if not pivot_dict_spot:
        pivot_dict_spot = pd.read_pickle(raw_data_path / 'market_pivot_spot.pkl')
        
    pivot_dict_swap = load_pivot_data(raw_data_path, 'swap')
    if not pivot_dict_swap:
        pivot_dict_swap = pd.read_pickle(raw_data_path / 'market_pivot_swap.pkl')

    step6_simulate_performance(conf, df_spot_ratio, df_swap_ratio, pivot_dict_spot, pivot_dict_swap, if_show_plot=True)
    logger.ok(f'å®Œæˆï¼Œå›æµ‹æ—¶é—´ï¼š{time.time() - r_time:.3f}ç§’')


def run_backtest_multi(factory: BacktestConfigFactory):
    # ====================================================================================================
    # 1. å‡†å¤‡å·¥ä½œ
    # ====================================================================================================
    iter_results_folder = factory.result_folder

    # åˆ é™¤ç¼“å­˜
    shutil.rmtree(iter_results_folder, ignore_errors=True)
    iter_results_folder.mkdir(parents=True, exist_ok=True)

    conf_list = factory.config_list
    for index, conf in enumerate(conf_list):
        logger.debug(f'â„¹ï¸ ç­–ç•¥{index + 1}ï½œå…±{len(conf_list)}ä¸ª')
        logger.debug(f'{conf.get_fullname()}')
        conf.save()
    logger.ok('ç­–ç•¥æ± ä¸­éœ€è¦å›æµ‹çš„ç­–ç•¥æ•°ï¼š{}'.format(len(conf_list)))

    # è®°å½•ä¸€ä¸‹æ—¶é—´æˆ³
    all_start_time = time.time()
    r_time = all_start_time

    # ====================================================================================================
    # 2. è¯»å–å›æµ‹æ‰€éœ€æ•°æ®ï¼Œå¹¶åšç®€å•çš„é¢„å¤„ç†
    # ====================================================================================================
    divider('è¯»å–æ•°æ®', sep='-')
    s_time = time.time()
    conf_all = factory.generate_all_factor_config()

    # è¯»å–æ•°æ®
    # é’ˆå¯¹ç°è´§ç­–ç•¥å’Œéç°è´§ç­–ç•¥è¯»å–çš„é€»è¾‘å®Œå…¨ä¸åŒã€‚
    # - å¦‚æœæ˜¯çº¯åˆçº¦æ¨¡å¼ï¼Œåªéœ€è¦è¯»å…¥ swap æ•°æ®å¹¶ä¸”åˆå¹¶å³å¯
    # - å¦‚æœæ˜¯ç°è´§æ¨¡å¼ï¼Œéœ€è¦è¯»å…¥ spot å’Œ swap æ•°æ®å¹¶ä¸”åˆå¹¶ï¼Œç„¶åæ·»åŠ  tag
    load_spot_and_swap_data(conf_all)  # ä¸²è¡Œæ–¹å¼ï¼Œå®Œå…¨ç­‰ä»·
    logger.ok(f'å®Œæˆè¯»å–æ•°æ®ä¸­å¿ƒæ•°æ®ï¼ŒèŠ±è´¹æ—¶é—´ï¼š{time.time() - s_time:.3f}ç§’')

    # ====================================================================================================
    # 3. è®¡ç®—å› å­
    # ====================================================================================================
    divider('æ—¶åºå› å­è®¡ç®—', sep='-')
    s_time = time.time()
    calc_factors(conf_all)  # æ‰§è¡Œæ—¶åºå› å­è®¡ç®—
    logger.ok(f'å®Œæˆè®¡ç®—æ—¶åºå› å­ï¼ŒèŠ±è´¹æ—¶é—´ï¼š{time.time() - s_time:.3f}ç§’ï¼Œç´¯è®¡æ—¶é—´ï¼š{(time.time() - r_time):.3f}ç§’')

    # è®¡ç®—æˆªé¢å› å­
    s_time = time.time()
    divider(f'æˆªé¢å› å­è®¡ç®—', sep='-')
    calc_cross_sections(conf_all)  # æ‰§è¡Œæˆªé¢å› å­è®¡ç®—
    logger.ok(f'å®Œæˆè®¡ç®—æˆªé¢å› å­ï¼ŒèŠ±è´¹æ—¶é—´ï¼š{time.time() - s_time:.3f}ç§’ï¼Œç´¯è®¡æ—¶é—´ï¼š{(time.time() - r_time):.3f}ç§’')

    # ====================================================================================================
    # 4. é€‰å¸
    # ====================================================================================================
    divider('é€‰å¸', sep='-')
    s_time = time.time()
    
    # [V2 - L6 æè‡´ä¼˜åŒ–] ç»Ÿä¸€å› å­æ•°æ®å¤§åˆå¹¶ (Master Data Assembly)
    # åœ¨è¿™é‡Œä¸€æ¬¡æ€§æŠŠæ‰€æœ‰ shard å’Œæˆªé¢å› å­çš„ Parquet å…¨åŠ è½½è¿›æ¥å¹¶ Join å¥½
    # è¿™æ ·å­ç­–ç•¥åœ¨é€‰å¸æ—¶å°±ä¸éœ€è¦å†åšä»»ä½•ç¡¬ç›˜ IO æˆ– Joinï¼Œé€Ÿåº¦å°†æå‡ä¸€ä¸ªæ•°é‡çº§
    logger.debug("ğŸ’¿ æ­£åœ¨æ„å»ºå…¨å±€ Master Factor æ•°æ®é›† (Zero-Wait Selection)...")
    from core.select_coin import ALL_KLINE_PATH_TUPLE
    from core.utils.path_kit import get_file_path
    import polars as pl
    
    all_kline_pq = get_file_path(*ALL_KLINE_PATH_TUPLE, as_path_type=True).with_suffix('.parquet')
    if all_kline_pq.exists():
        master_pl = pl.read_parquet(all_kline_pq)
        cache_dir = get_file_path('data', 'cache', as_path_type=True)
        
        # 1. åˆå¹¶æ‰€æœ‰æ—¶åºå› å­åˆ†ç‰‡
        for shard_file in cache_dir.glob('factors_shard_*.parquet'):
            f_df = pl.read_parquet(shard_file)
            # åªå–ä¸»é›†ä¸­ä¸å­˜åœ¨çš„å› å­åˆ—è¿›è¡Œ Join
            cols = [c for c in f_df.columns if c not in master_pl.columns and c not in ['candle_begin_time', 'symbol', 'is_spot']]
            if cols:
                master_pl = master_pl.join(f_df.select(['candle_begin_time', 'symbol', 'is_spot'] + cols), 
                                         on=['candle_begin_time', 'symbol', 'is_spot'], how='left')
        
        # 2. åˆå¹¶æ‰€æœ‰ç‹¬ç«‹æˆªé¢å› å­
        for factor_pq in cache_dir.glob('factor_*.parquet'):
            f_df = pl.read_parquet(factor_pq)
            cols = [c for c in f_df.columns if c not in master_pl.columns and c not in ['candle_begin_time', 'symbol', 'is_spot']]
            if cols:
                master_pl = master_pl.join(f_df.select(['candle_begin_time', 'symbol', 'is_spot'] + cols), 
                                         on=['candle_begin_time', 'symbol', 'is_spot'], how='left')
        
        # æœ€ç»ˆè½¬å› Pandas äº¤ä»˜ç»™é€‰å¸å¼•æ“
        master_shared_df = master_pl.to_pandas()
        del master_pl
    else:
        master_shared_df = None

    # [V2 - L4 ä¼˜åŒ–] å¹¶è¡ŒåŒ–å¤šç­–ç•¥é€‰å¸
    from concurrent.futures import ThreadPoolExecutor, as_completed
    with ThreadPoolExecutor(max_workers=min(len(factory.config_list), job_num)) as executor:
        f_list = [executor.submit(select_coins, conf, True, master_shared_df) for conf in factory.config_list]
        for _ in as_completed(f_list):
            pass

    logger.ok(f'å®Œæˆé€‰å¸ï¼ŒèŠ±è´¹æ—¶é—´ï¼š{time.time() - s_time:.3f}ç§’ï¼Œç´¯è®¡æ—¶é—´ï¼š{(time.time() - r_time):.3f}ç§’')

    # ====================================================================================================
    # 5. é’ˆå¯¹é€‰å¸ç»“æœè¿›è¡Œèšåˆ
    # ====================================================================================================
    divider('å­ç­–ç•¥æ¨¡æ‹Ÿ', sep='-')
    logger.setLevel(logging.DEBUG)
    logger.debug(f'æ³¨æ„ï¼šä¸»è¦å’Œé€‰å¸æ•°é‡æœ‰å…³...')
    s_time = time.time()
    
    # V2 ä¼˜åŒ–: é¢„å…ˆåŠ è½½å¹¶æŒ‰æ—¶é—´å¯¹é½ Pivot æ•°æ® (L3 çº§å…±äº«å†…å­˜ä¼˜åŒ–)
    logger.debug("ğŸ’¿ æ­£åœ¨åˆå§‹åŒ–é¢„å¯¹é½ Pivot æ¨¡æ‹Ÿæ•°æ® (Time-Aligned)...")
    p_s_time = time.time()
    
    # ç¡®å®šå›æµ‹çš„æ—¶é—´èŒƒå›´ï¼Œç”¨äºé¢„å…ˆè£åˆ‡ Pivot æ•°æ®
    # æˆ‘ä»¬ä»¥ç¬¬ä¸€ä¸ª config çš„æ—¶é—´èŒƒå›´ä¸ºå‡†ï¼ˆå‡è®¾å¤šç­–ç•¥å›æµ‹æ—¶é—´èŒƒå›´ä¸€è‡´ï¼‰
    test_start = pd.to_datetime(conf_list[0].start_date)
    test_end = pd.to_datetime(conf_list[0].end_date)
    
    raw_pivot_spot = load_pivot_data(raw_data_path, 'spot')
    raw_pivot_swap = load_pivot_data(raw_data_path, 'swap')
    
    # é¢„å…ˆæŒ‰æ—¶é—´è£åˆ‡ï¼Œè¿™æ ·å­ç­–ç•¥æ¨¡æ‹Ÿåªéœ€è¦æŒ‰å¸ç§ (columns) è£åˆ‡ï¼Œé€Ÿåº¦æå¿«
    global_pivot_spot = {k: df.loc[test_start:test_end] for k, df in raw_pivot_spot.items()}
    global_pivot_swap = {k: df.loc[test_start:test_end] for k, df in raw_pivot_swap.items()}
    
    logger.debug(f"âœ… å…¨å¯¹é½ Pivot æ•°æ®å‡†å¤‡å®Œæˆï¼Œè€—æ—¶: {time.time() - p_s_time:.2f}s")

    # [V2 - L4 ä¼˜åŒ–] å¹¶è¡ŒåŒ–å¤šç­–ç•¥æ¨¡æ‹Ÿ (ä¿æŒé¡ºåº)
    report_list = [None] * len(conf_list)
    with ThreadPoolExecutor(max_workers=min(len(conf_list), job_num)) as executor:
        future_to_idx = {
            executor.submit(simu_performance_on_select, conf, False, global_pivot_spot, global_pivot_swap): i 
            for i, conf in enumerate(conf_list)
        }
        for future in as_completed(future_to_idx):
            idx = future_to_idx[future]
            report_list[idx] = future.result()

    if len([r for r in report_list if r is not None]) > 65535:
        logger.debug(f'å›æµ‹æŠ¥è¡¨æ•°é‡ä¸º {len(report_list)}ï¼Œè¶…è¿‡ 65535ï¼Œåç»­å¯èƒ½ä¼šå ç”¨æµ·é‡å†…å­˜')
    total_duration = time.time() - all_start_time
    logger.ok(f'--- æ€»ä½“å›æµ‹ç»“æŸï¼Œæ€»è®¡è€—æ—¶ï¼š{total_duration:.2f}s ---')
    
    return report_list
