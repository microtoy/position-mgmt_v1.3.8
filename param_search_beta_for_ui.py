"""
é‚¢ä¸è¡Œï½œç­–ç•¥åˆ†äº«ä¼š
ä»“ä½ç®¡ç†æ¡†æ¶

ç‰ˆæƒæ‰€æœ‰ Â©ï¸ é‚¢ä¸è¡Œ
å¾®ä¿¡: xbx1717

æœ¬ä»£ç ä»…ä¾›ä¸ªäººå­¦ä¹ ä½¿ç”¨ï¼Œæœªç»æˆæƒä¸å¾—å¤åˆ¶ã€ä¿®æ”¹æˆ–ç”¨äºå•†ä¸šç”¨é€”ã€‚

Author: é‚¢ä¸è¡Œ
"""
import copy
import itertools
import json
import re
import time
import warnings
from typing import List

import pandas as pd

from config import raw_data_path
from core.backtest import step6_simulate_performance
from core.model.backtest_config import MultiEquityBacktestConfig
from core.utils.log_kit import logger, divider
from core.utils.path_kit import get_file_path
from core.version import version_prompt

# ====================================================================================================
# ** è„šæœ¬è¿è¡Œå‰é…ç½® **
# ä¸»è¦æ˜¯è§£å†³å„ç§å„æ ·å¥‡æ€ªçš„é—®é¢˜ä»¬
# ====================================================================================================
warnings.filterwarnings('ignore')  # è¿‡æ»¤ä¸€ä¸‹warningsï¼Œä¸è¦å“åˆ°è€å®äºº

# pandasç›¸å…³çš„æ˜¾ç¤ºè®¾ç½®ï¼ŒåŸºç¡€è¯¾ç¨‹éƒ½æœ‰ä»‹ç»
pd.set_option('display.max_rows', 1000)
pd.set_option('expand_frame_repr', False)  # å½“åˆ—å¤ªå¤šæ—¶ä¸æ¢è¡Œ
pd.set_option('display.unicode.ambiguous_as_wide', True)  # è®¾ç½®å‘½ä»¤è¡Œè¾“å‡ºæ—¶çš„åˆ—å¯¹é½åŠŸèƒ½
pd.set_option('display.unicode.east_asian_width', True)


def dict_itertools(dict_):
    filter_dict = {k: v for k, v in dict_.items() if isinstance(v, list) and len(v) > 0}
    keys = list(filter_dict.keys())
    values = list(filter_dict.values())
    return [dict(zip(keys, combo)) for combo in itertools.product(*values)]


def __parse_path_expression(path_expr):
    """è§£æè·¯å¾„è¡¨è¾¾å¼ï¼Œå¦‚ 'factor_list[0][2][0]'

    Args:
        path_expr: è·¯å¾„è¡¨è¾¾å¼å­—ç¬¦ä¸²

    Returns:
        tuple: (base_key, indices)
        - base_key: åŸºç¡€é”®åï¼Œå¦‚ 'factor_list'
        - indices: ç´¢å¼•åˆ—è¡¨ï¼Œå¦‚ [0, 2, 0]
    """
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…åŸºç¡€é”®åå’Œæ‰€æœ‰ç´¢å¼•
    match = re.match(r"^([^[]+)((?:\[\d+\])+)$", path_expr)
    if not match:
        return path_expr, []

    base_key = match.group(1)
    indices_str = match.group(2)

    # æå–æ‰€æœ‰æ•°å­—ç´¢å¼•
    indices = [int(idx) for idx in re.findall(r"\[(\d+)\]", indices_str)]

    return base_key, indices


def __set_nested_value(obj, base_key, indices, value):
    """æ ¹æ®è·¯å¾„è®¾ç½®åµŒå¥—æ•°æ®ç»“æ„ä¸­çš„å€¼

    Args:
        obj: ç›®æ ‡å¯¹è±¡ï¼ˆå­—å…¸ï¼‰
        base_key: åŸºç¡€é”®å
        indices: ç´¢å¼•åˆ—è¡¨
        value: è¦è®¾ç½®çš„å€¼
    """
    if base_key not in obj['params']:
        return

    current = obj['params'][base_key]

    # å¯¼èˆªåˆ°æœ€åä¸€å±‚çš„çˆ¶çº§
    for idx in indices[:-1]:
        if isinstance(current, list) and 0 <= idx < len(current):
            current = current[idx]
        else:
            return

    # è®¾ç½®æœ€åä¸€å±‚çš„å€¼
    final_idx = indices[-1]
    if 0 <= final_idx < len(current):
        if isinstance(current, (list, tuple)):
            current = list(current)
            current[final_idx] = value
            current = tuple(current)
        else:
            current[final_idx] = value

    obj['params'][base_key][indices[:-1][0]] = current


def convert_range_params(data):
    """è½¬æ¢rangeæ ¼å¼çš„å‚æ•°ä¸ºåˆ—è¡¨

    Args:
        data: é…ç½®æ•°æ®ï¼ˆé€šå¸¸æ˜¯å­—å…¸ï¼‰

    Returns:
        è½¬æ¢åçš„æ•°æ®
    """
    if isinstance(data, dict):
        # æ£€æŸ¥æ˜¯å¦æ˜¯rangeæ ¼å¼ {"start": x, "end": y, "step": z}
        if all(key in data for key in ["start", "end", "step"]):
            start = data["start"]
            end = data["end"]
            step = data["step"]
            return list(range(start, end, step))
        else:
            # é€’å½’å¤„ç†å­—å…¸ä¸­çš„æ¯ä¸ªå€¼
            return {k: convert_range_params(v) for k, v in data.items()}
    elif isinstance(data, list):
        # é€’å½’å¤„ç†åˆ—è¡¨ä¸­çš„æ¯ä¸ªå…ƒç´ 
        return [convert_range_params(item) for item in data]
    else:
        # å…¶ä»–ç±»å‹ç›´æ¥è¿”å›
        return data


def convert_lists_to_tuples(data, target_fields=None):
    """å°†æŒ‡å®šå­—æ®µä¸­çš„åˆ—è¡¨é‡Œçš„åˆ—è¡¨è½¬æ¢ä¸ºå…ƒç»„

    Args:
        data: å­—å…¸æ•°æ®
        target_fields: éœ€è¦å¤„ç†çš„å­—æ®µé›†åˆï¼Œé»˜è®¤ä¸ºNoneæ—¶å¤„ç†æ‰€æœ‰å­—æ®µ

    Returns:
        å¤„ç†åçš„æ•°æ®
    """
    if not isinstance(data, dict):
        return data

    # é»˜è®¤çš„å…ƒç»„å­—æ®µ
    if target_fields is None:
        target_fields = {
            "factor_list",
            "long_factor_list",
            "short_factor_list",
            "filter_list",
            "long_filter_list",
            "short_filter_list",
            "filter_list_post",
            "long_filter_list_post",
            "short_filter_list_post",
        }

    # æ·±æ‹·è´ä»¥é¿å…ä¿®æ”¹åŸæ•°æ®
    result = copy.deepcopy(data)

    for field in target_fields:
        if field in result and isinstance(result[field], list):
            result[field] = [
                tuple(item) if isinstance(item, list) else item
                for item in result[field]
            ]

    return result


def find_best_params(strategies: List[dict], strategy_info):
    # ====================================================================================================
    # ** 1. åˆå§‹åŒ– **
    # æ ¹æ® config.py ä¸­çš„é…ç½®ï¼Œåˆå§‹åŒ–å›æµ‹
    # ====================================================================================================
    # éœ€è¦æºå¸¦æ‰€æœ‰å›æµ‹ç»„çš„å› å­åˆ—è¡¨
    default_strategy = copy.deepcopy(strategy_info.get('strategy_config'))
    factor_list = set()
    for strategy in strategies:
        factor_list = factor_list | set(strategy.get('params', {}).get('factor_list', []))
        default_strategy['hold_period'] = strategy['hold_period']
        default_strategy['name'] = strategy['name']
    default_strategy['params']['factor_list'] = factor_list

    # ç”¨èšåˆçš„æ•°æ®è¿›è¡Œme confåˆå§‹åŒ–
    me_conf = MultiEquityBacktestConfig(
        name=backtest_name,
        strategy_config=default_strategy,
        strategies=strategy_info['strategy_pool'],
        leverage=strategy_info['leverage'],
    )

    # ====================================================================================================
    # ** 2. å­ç­–ç•¥å›æµ‹ **
    # è¿è¡Œå­ç­–ç•¥å›æµ‹ï¼Œè®¡ç®—æ¯ä¸€ä¸ªå­ç­–ç•¥çš„èµ„é‡‘æ›²çº¿
    # ğŸ’¡å°æŠ€å·§ï¼šå¦‚æœä½ ä»“ä½ç®¡ç†çš„å­ç­–ç•¥ä¸å˜åŒ–ï¼Œè°ƒè¯•çš„æ—¶å€™å¯ä»¥æ³¨é‡Šè¿™ä¸ªæ­¥éª¤ï¼Œå¯ä»¥åŠ å¿«è°ƒè¯•çš„é€Ÿåº¦
    # ====================================================================================================
    me_conf.backtest_strategies()

    # ====================================================================================================
    # ** 3. æ•´ç†å­ç­–ç•¥çš„èµ„é‡‘æ›²çº¿ **
    # è·å–æ‰€æœ‰å­ç­–ç•¥çš„èµ„é‡‘æ›²çº¿ä¿¡æ¯ï¼Œå¹¶ä¸”é’ˆå¯¹ä»“ä½ç®¡ç†ç­–ç•¥åšå‘¨æœŸè½¬æ¢ï¼Œå¹¶è®¡ç®—å› å­
    # ====================================================================================================
    me_conf.process_equities()

    # ====================================================================================================
    # ** 4. åˆå§‹åŒ–éå†çš„é…ç½®åˆ—è¡¨ **
    # ====================================================================================================
    divider('åˆå§‹åŒ–éå†', sep='-')
    logger.warning(f'å­ç­–ç•¥ç»“æœä»åœ¨ {me_conf.factory.result_folder} ä¸­(èŠ‚çº¦å­˜å‚¨)')
    me_conf_list: List[MultiEquityBacktestConfig] = []
    for index, strategy in enumerate(strategies):
        new_me_conf = MultiEquityBacktestConfig.duplicate_conf(me_conf, f'{backtest_name}_å‚æ•°{index + 1}', strategy)
        me_conf_list.append(new_me_conf)

    # ====================================================================================================
    # ** 5. é€ä¸ªè¿›è¡Œä»“ä½ç®¡ç†å›æµ‹ **
    # ====================================================================================================
    divider('é€ä¸ªå›æµ‹', sep='-')
    pivot_dict_spot = pd.read_pickle(raw_data_path / 'market_pivot_spot.pkl')
    pivot_dict_swap = pd.read_pickle(raw_data_path / 'market_pivot_swap.pkl')

    report_list = []
    for i, me_conf_i in enumerate(me_conf_list):
        # ====================================================================================================
        # ** 5-1. è®¡ç®—ä»“ä½æ¯”ä¾‹ **
        # ä»“ä½ç®¡ç†ç­–ç•¥æ¥å…¥ï¼Œè®¡ç®—æ¯ä¸€ä¸ªæ—¶é—´å‘¨æœŸä¸­ï¼Œå­ç­–ç•¥åº”è¯¥æŒä»“çš„èµ„é‡‘æ¯”ä¾‹
        # ====================================================================================================
        seq = f'({i + 1} / {len(me_conf_list)})'
        logger.debug(f'ğŸ—„ï¸ {seq} {me_conf_i}')
        s_time = time.time()
        pos_ratio = me_conf_i.calc_ratios()

        # ====================================================================================================
        # ** 5-2. èšåˆé€‰å¸ç»“æœ **
        # æ ¹æ®å­ç­–ç•¥çš„èµ„é‡‘æ¯”ä¾‹ï¼Œé‡æ–°èšåˆæˆä¸€ä¸ªé€‰å¸ç»“æœï¼ŒåŠå¯¹åº”å‘¨æœŸå†…å¸ç§çš„èµ„é‡‘åˆ†é…
        # ====================================================================================================
        df_spot_ratio, df_swap_ratio = me_conf_i.agg_pos_ratio(pos_ratio)
        logger.ok(f'å®Œæˆä»“ä½ç®¡ç†æ¨¡å—çš„è®¡ç®—ï¼Œå·²èŠ±è´¹æ—¶é—´{time.time() - s_time:.3f}ç§’')

        # ====================================================================================================
        # ** 5-3. æ¨¡æ‹Ÿäº¤æ˜“ **
        # æ ¹æ®ç”Ÿæˆå¥½çš„é€‰å¸ç»“æœ+èµ„é‡‘é…æ¯”ï¼Œé‡æ–°æ¨¡æ‹Ÿäº¤æ˜“ï¼Œå¾—åˆ°å›æµ‹æŠ¥å‘Š
        # ====================================================================================================
        conf_all = me_conf_i.factory.generate_all_factor_config()
        conf_all.name = me_conf_i.factory.backtest_name
        # ç”¨äºå‚æ•°éå†åœºæ™¯
        conf_all.is_param_search = True

        # è®©æˆ‘ä»¬è¡èµ·åŒæ¡¨ğŸµï½
        report = step6_simulate_performance(
            conf_all,
            df_spot_ratio, df_swap_ratio, pivot_dict_spot, pivot_dict_swap,
            if_show_plot=False,  # æ˜¯å¦æ˜¾ç¤ºå›¾è¡¨
            description=str(me_conf),  # å›¾è¡¨æè¿°æ›¿æ¢ä¸ºä»“ä½ç®¡ç†ç­–ç•¥
        )

        report_list.append(report)

        logger.ok(f'{seq} {me_conf_i}')

    # ====================================================================================================
    # 6. å±•ç¤ºæœ€ä¼˜å‚æ•°
    # - æ ¹æ®å›æµ‹ç»“æœç­›é€‰æœ€ä¼˜å‚æ•°ç»„åˆï¼Œå¹¶ä¿å­˜åˆ° Excel æ–‡ä»¶
    # ====================================================================================================
    divider('å±•ç¤ºæœ€ä¼˜å‚æ•°', sep='-')
    s_time = time.time()
    if len(report_list) > 65535:
        logger.warning(f'å›æµ‹å‚æ•°åˆ—è¡¨è¶…è¿‡ 65535ï¼Œä¼šå ç”¨å¤§é‡å†…å­˜ï¼Œè¯·æ‰‹åŠ¨åˆå¹¶ç»“æœ')
        return None

    all_params_map = pd.concat(report_list, ignore_index=True)
    report_cols = all_params_map.columns
    all_me_conf_name_list = [me_conf_i.factory.backtest_name for me_conf_i in me_conf_list]
    all_me_conf_str_list = [str(me_conf_i) for me_conf_i in me_conf_list]
    all_params_map['ä»“ä½ç®¡ç†ç­–ç•¥'] = all_me_conf_str_list
    all_params_map = all_params_map.assign(
        ç­–ç•¥å=all_me_conf_name_list,
        ä»“ä½ç®¡ç†å‚æ•°=all_me_conf_str_list
    )

    # åˆå¹¶å‚æ•°ç»†èŠ‚
    # æŒ‰ç´¯ç§¯å‡€å€¼æ’åºå¹¶ä¿å­˜ç»“æœ
    all_params_map.sort_values(by='ç´¯ç§¯å‡€å€¼', ascending=False, inplace=True)
    all_params_map = all_params_map[['ç­–ç•¥å', 'ä»“ä½ç®¡ç†ç­–ç•¥', *report_cols]].drop(columns=['param'])
    all_params_map.to_excel(get_file_path('data', backtest_name, 'æœ€ä¼˜å‚æ•°.xlsx'), index=False)
    print(all_params_map)
    logger.ok(f'å®Œæˆå±•ç¤ºæœ€ä¼˜å‚æ•°ï¼ŒèŠ±è´¹æ—¶é—´ï¼š{time.time() - s_time:.3f}ç§’ï¼Œç´¯è®¡æ—¶é—´ï¼š{(time.time() - s_time):.3f}ç§’')


if __name__ == '__main__':
    version_prompt()
    print()
    divider('[ä»“ä½ç®¡ç†æ¡†æ¶éå†è„šæœ¬_beta]', with_timestamp=False)
    logger.debug(f'# æœ¬è„šæœ¬ä¸º BETA ç‰ˆæœ¬ï¼Œç›®å‰å­˜åœ¨ä¸€ä¸ªå·²çŸ¥é—®é¢˜ï¼š')
    logger.debug(f'# æœ¬è„šæœ¬èšåˆéå†çš„å‚æ•°è¿›è¡Œè®¡ç®—ï¼Œåœ¨å¤„ç†è½®åŠ¨å› å­æ—¶ï¼Œä¼šæ¸…ç†ç©ºå€¼æ•°æ®ï¼Œè¿™é‡Œä¼šæŒ‰ç…§éå†çš„æœ€å¤§å‚æ•°è¿›è¡Œå¤„ç†')
    logger.debug(f'# å› æ­¤ï¼Œæœ¬è„šæœ¬éå†ä¹‹åçš„ç»“æœä¼šå‡ºç°ä¸ç›´æ¥è·‘å›æµ‹å­˜åœ¨éƒ¨åˆ†è¯¯å·®')
    divider('[ä»“ä½ç®¡ç†æ¡†æ¶éå†è„šæœ¬_beta]', with_timestamp=False)

    # ====================================================================================================
    # backtest_nameå’Œstrategy_pooléƒ½é»˜è®¤ä½¿ç”¨config.pyä¸­çš„åŒåå˜é‡
    # ====================================================================================================
    with open(get_file_path("config.json"), "r", encoding="utf-8") as f:
        batch = json.load(f)
    # è½¬æ¢rangeæ ¼å¼çš„å‚æ•°ä¸ºåˆ—è¡¨
    batch = convert_range_params(batch)

    backtest_name = batch.get("search_name", "éå†")

    strategy_config_list = []
    for param_dict in dict_itertools(batch):
        strategy_config = copy.deepcopy(batch.get('strategy_info').get('strategy_config'))
        # æ›´æ–°å¯éå†çš„å‚æ•°
        for param_key, param_value in param_dict.items():
            if not param_value:  # è·³è¿‡ç©ºå€¼
                continue

            # æ£€æŸ¥æ˜¯å¦æ˜¯è·¯å¾„è¡¨è¾¾å¼
            base_key, indices = __parse_path_expression(param_key)

            if indices:  # å¦‚æœæ˜¯è·¯å¾„è¡¨è¾¾å¼ï¼ˆåŒ…å«ç´¢å¼•ï¼‰
                __set_nested_value(strategy_config, base_key, indices, param_value)
                logger.info(f"æ›´æ–°è·¯å¾„è¡¨è¾¾å¼ {param_key}: {param_value}")
            else:  # ä¼ ç»Ÿçš„ç›´æ¥é”®å€¼å¯¹
                # å¤„ç†ä¼ ç»Ÿçš„å‚æ•°æ›´æ–°é€»è¾‘
                strategy_config[param_key] = param_value

        # ç»Ÿä¸€è½¬æ¢ params ä¸­çš„åˆ—è¡¨å…ƒç´ ä¸ºå…ƒç»„
        strategy_config['params'] = convert_lists_to_tuples(strategy_config['params'])

        strategy_config_list.append(strategy_config)

    find_best_params(strategy_config_list, copy.deepcopy(batch.get('strategy_info')))
